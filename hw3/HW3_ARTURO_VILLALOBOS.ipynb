{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from  datascience import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_score\n",
    "from random import choices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors    import KNeighborsClassifier \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, accuracy_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: (Theoretical question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now review $k$-fold cross-validation.\n",
    "\n",
    "(a) Explain how $k$-fold cross-validation is implemented in steps.\n",
    "\n",
    "(b) What are the advantages and disadvantages of $k$-fold crossvalidation\n",
    "relative to:\n",
    "\n",
    "i. The validation set approach?\n",
    "\n",
    "ii. LOOCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a\n",
    "    - k-fold cross validation works in a simular way to LOOCV how ever instead of having n-samples , we split our data up into k chuncks where each sample is comprised of test and traing data  \n",
    "- b \n",
    "    - one advantange of k-fold relative to LOOCV is that it is way less computationally expensive due to the fact that we are not making a new model n times , we are taking k samples where k<n then using those samples to each train and test a model to approximate various parameters. The advantage over a validation set approach is that our approximations approach the accuracy of the estimates we get from LOOCV. A small disadvantage is that for each sample there will be slightly more bias relative to a sample from LOOCV because there is less training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: (Programming question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous chapter we used logistic regression to predict the probability of `default` using `income` and `balance` on the `Default` data set. Estimate the test error and Decision Boundary of this logistic regression model using the `validation set` approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Default = pd.read_csv(\"Default.csv\")\n",
    "default = Default.values[:,1]\n",
    "Balance = Default.values[:,3]\n",
    "Income  = Default.values[:,4]\n",
    "y       = Default.default.factorize()[0]\n",
    "X       = Default.values[:,3:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i). Do not forget to set a random seed before beginning your analysis. Split the sample set into a `training set` and a `validation set`.\n",
    "\n",
    "(ii) Fit a logistic regression model that uses income and balance to predict default using only the training observations.\n",
    "\n",
    "(iii). Obtain a prediction of default status for each individual in the validation set \n",
    "\n",
    "(iv). Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.\n",
    "\n",
    "(v) State the Decision Boundary of the Logistic Regression: \n",
    "\n",
    "(vi) Plot the data with X Axis as Balance and Y Axis as Income. Put blue color for Non -Defaulters and Red colors for defaulters. Name the X Axis as Balance and Y Axis as Income. \n",
    "\n",
    "(vi). Generate 10 different validation set and training set and calculate the variability of the test error estimate across 10 different validation set. Remove doing the np.random.seed() in the loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04479999999999995"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "# split data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5)\n",
    "# fit model\n",
    "model = LogisticRegression(solver = 'newton-cg')\n",
    "model.fit(X_train,y_train)\n",
    "# prediction\n",
    "y_pred = model.predict(X_train)\n",
    "# compute error\n",
    "score =  1- accuracy_score(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.06423194052087+0.005424658644462365x1 + 1.9838262810826255e-05x2 = 0\n"
     ]
    }
   ],
   "source": [
    "intercept = model.intercept_ \n",
    "slope1 = model.coef_[0,0]\n",
    "slope2 = model.coef_[0,1]\n",
    "\n",
    "\n",
    "print(str(intercept[0]) + '+' + str(slope1)+'x1' + ' + ' + str(slope2)+'x2' + ' = ' + '0' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([11.06423/model.coef_,11.06423/model.coef_,11.06423/model.coef_])\n",
    "y = np.array([np.min(Income),np.max(Income),np.mean(Income)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2-D, but have shapes (3, 1, 2) and (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-455f04cad903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2761\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m   2763\u001b[0m         is not None else {}), **kwargs)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             raise ValueError(f\"x and y can be no greater than 2-D, but have \"\n\u001b[0m\u001b[1;32m    346\u001b[0m                              f\"shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y can be no greater than 2-D, but have shapes (3, 1, 2) and (3,)"
     ]
    }
   ],
   "source": [
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2-D, but have shapes (3, 1, 2) and (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ef93f25d9924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2761\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m   2763\u001b[0m         is not None else {}), **kwargs)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             raise ValueError(f\"x and y can be no greater than 2-D, but have \"\n\u001b[0m\u001b[1;32m    346\u001b[0m                              f\"shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y can be no greater than 2-D, but have shapes (3, 1, 2) and (3,)"
     ]
    }
   ],
   "source": [
    "plt.scatter(X_train[y_train==0,0],X_train[y_train==0,1],color = 'blue')\n",
    "plt.scatter(X_train[y_train==1,0],X_train[y_train==1,1],color = 'bred')\n",
    "plt.plot(x,y,linewidth = 4, color = 'black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for some reason my plots arent showing here are the trouble shooing steps i followed:\n",
    "- pip3 uninstall matplotlib\n",
    "- pip3 install matplotlib\n",
    "matplotlib-3.3.2 is the version i am using \n",
    "the plots above should yield the correct results\n",
    "i tried to install an older version of matplotlib\n",
    "- i did pip3 install matplotlib==3.2\n",
    "so far i have had no luck "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006399999999999954"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error = make_array()\n",
    "\n",
    "for repeat in np.arange(10):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5)\n",
    "    model = LogisticRegression(solver = 'newton-cg')\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    score = 1- accuracy_score(y_test, y_pred)\n",
    "    test_error = np.append(test_error, score)\n",
    "np.std(test_error)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : (Programming question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform cross-validation on a simulated data set.\n",
    "\n",
    "(a) Generate a simulated data set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)  # Random numbers generated by Python are different from those generated by R, as mentioned in Exercise 3.11\n",
    "x = np.random.normal(size=100)\n",
    "epsilon = np.random.normal(size=100)\n",
    "\n",
    "y = x - 2 * x**2 + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set, what is $n$ and what is $p$? Write out the model\n",
    "used to generate the data in equation form.\n",
    "\n",
    "(b) Create a scatterplot of $X$ against $Y$. Comment on what you find.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Set a random seed, and then compute the LOOCV errors that\n",
    "result from fitting the following four models using least squares:\n",
    "\n",
    "$$\\begin{align*}\n",
    "i. Y &= β0 + β1X + \\epsilon \\\\\n",
    "ii. Y &= β0 + β1X + β2X^2 + \\epsilon \\\\\n",
    "iii. Y &= β0 + β1X + β2X^2 + β3X^3 + \\epsilon \\\\\n",
    "iv. Y &= β0 + β1X + β2X^2 + β3X^3 + β4X^4 + \\epsilon. \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Note you may find it helpful to use the `data.frame()` function\n",
    "to create a single data set containing both $X$ and $Y$ .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize data into a dataframe (easier to handle)\n",
    "df = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "# Initiate variables\n",
    "min_deg = 1  # Minimum degree of the polynomial equations considered\n",
    "max_deg = 4+1  # Maximum degree of the polynomial equations considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (MSE): 6.260764\n",
      "Model 2 (MSE): 0.914290\n",
      "Model 3 (MSE): 0.926877\n",
      "Model 4 (MSE): 0.866912\n"
     ]
    }
   ],
   "source": [
    "## method 1: \n",
    "\n",
    "# Set new random seed\n",
    "np.random.seed(20)\n",
    "\n",
    "model = LinearRegression()\n",
    "loo = LeaveOneOut()\n",
    "scores = np.array([])\n",
    "\n",
    "# Compute mean squared error (MSE) for the different polynomial equations.\n",
    "for i in range(min_deg, max_deg):\n",
    "    # Leave-one-out cross validation \n",
    "    for train, test in loo.split(df):\n",
    "        X_train = df['x'][train].to_numpy().reshape(-1,1)\n",
    "        y_train = df['y'][train].to_numpy()\n",
    "        X_test = df['x'][test].to_numpy().reshape(-1,1)\n",
    "        y_test = df['y'][test].to_numpy()\n",
    "        \n",
    "        poly   = PolynomialFeatures(i) \n",
    "        X_train_poly = poly.fit_transform(X_train)\n",
    "        X_test_poly = poly.fit_transform(X_test)\n",
    "        model.fit(X_train_poly, y_train)\n",
    "        y_pred = model.predict(X_test_poly)\n",
    "\n",
    "        # MSE\n",
    "        score = mean_squared_error(y_test, y_pred)\n",
    "        scores= np.append(scores,score)\n",
    "    print('Model %i (MSE): %f' % (i,np.mean(scores)))\n",
    "    scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.46172316, -0.89727766, -0.93279051, -0.88994609])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## method 2, use the cross_val_score function directly\n",
    "# Initialize the model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Create LOOCV object\n",
    "loo = LeaveOneOut()\n",
    "scores = np.array([])\n",
    "\n",
    "for i in range(min_deg, max_deg):\n",
    "    poly   = PolynomialFeatures(i) \n",
    "    X_poly = poly.fit_transform(x.reshape(-1,1))\n",
    "    score  = cross_val_score(lm, X_poly, df.y, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "    scores = np.append(scores,score)\n",
    "\n",
    "# The output is negative MSE\n",
    "scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.46172316, -0.89727766, -0.93279051, -0.88994609])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "np.random.seed(3)\n",
    "# Create LOOCV object\n",
    "loo = LeaveOneOut()\n",
    "scores2 = np.array([])\n",
    "\n",
    "for i in range(min_deg, max_deg):\n",
    "    poly   = PolynomialFeatures(i) \n",
    "    X_poly = poly.fit_transform(x.reshape(-1,1))\n",
    "    score  = cross_val_score(lm, X_poly, df.y, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "    scores2 = np.append(scores2,score)\n",
    "\n",
    "# The output is negative MSE\n",
    "scores2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Repeat (c) using another random seed, and report your results.\n",
    "Are your results the same as what you got in (c)? Why?\n",
    "\n",
    "(e) Which of the models in (c) had the smallest LOOCV error? Is\n",
    "this what you expected? Explain your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- d\n",
    "    - after using a different random seed we get virtually the same results wich is not surprsing we are using LOOCV which mean that eventually the n sub samples will cover all the possible combonations of items being left out \n",
    "- e\n",
    "    -  the models that have the smallest LOOCV error are the 4 degree polynomials but even after the second order polonomial is modeled we dont see a decrease the the MSE from 2-3 as we see from 1-2 . The fact that the higher order polynomials have smaller MSEs is not surprising as they are more flexable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: (Programming question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now consider the `Boston` housing data set, the following code is used to import the `Boston` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['MEDV'] = pd.Series(boston.target)\n",
    "medv = df['MEDV']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Based on this data set, provide an estimate for the population\n",
    "mean of `medv`. Call this estimate $\\hat{\\mu}$.\n",
    "\n",
    "(b) Provide an estimate of the standard error of $\\hat{\\mu}$. Interpret this\n",
    "result.\n",
    "\n",
    "Hint: We can compute the standard error of the sample mean by\n",
    "dividing the sample standard deviation by the square root of the\n",
    "number of observations.\n",
    "\n",
    "(c) Now estimate the standard error of $\\hat{\\mu}$ using the bootstrap. How\n",
    "does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.402744400383397"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_times = 1000\n",
    "n = len(df)\n",
    "means = np.array([])\n",
    "for i in range(B_times):\n",
    "    x_bootstrap = choices(medv, k = n) ## draw samples with replacement\n",
    "    means = np.append(means, np.mean(x_bootstrap))\n",
    "np.std(means)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedmeans = sorted(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Based on your bootstrap estimate from (c), provide a 95% confidence\n",
    "interval for the mean of `medv`. \n",
    "\n",
    "Hint: You can approximate a 95% confidence interval using the\n",
    "formula $[\\hat{mu} − 2SE(\\hat{\\mu}), \\hat{\\mu} + 2SE(\\hat{\\mu})]$.\n",
    "\n",
    "(e) Based on this data set, provide an estimate, $\\hat{\\mu}_{med}$, for the median\n",
    "value of `medv` in the population.\n",
    "\n",
    "(f) We now would like to estimate the standard error of $\\hat{\\mu}_{med}$. Unfortunately,\n",
    "there is no simple formula for computing the standard\n",
    "error of the median. Instead, estimate the standard error of the\n",
    "median using the bootstrap. Comment on your findings.\n",
    "\n",
    "Hint: Similar as q(c)\n",
    "\n",
    "(g) Based on this data set, provide an estimate for the tenth percentile\n",
    "of `medv` in Boston suburbs. Call this quantity $\\hat{\\mu}_{0.1}$. (You\n",
    "can use the `quantile()` function.)\n",
    "\n",
    "(h) Use the bootstrap to estimate the standard error of $\\hat{\\mu}_{0.1}$. Comment\n",
    "on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for mdev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[21.735375494071146, 23.309090909090912]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_95_CI_medv = [sortedmeans[25], sortedmeans[975]]\n",
    "print('95% confidence interval for mdev')\n",
    "mu_95_CI_medv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median for whole medv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedset = sorted(medv)\n",
    "print('median for whole medv')\n",
    "sortedset[int(len(sortedset)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.199799999999996"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_times = 1000\n",
    "n = len(df)\n",
    "medians = np.array([])\n",
    "for i in range(B_times):\n",
    "    x_bootstrap = choices(medv, k = n) ## draw samples with replacement\n",
    "    x_bootsorted = sorted(x_bootstrap)\n",
    "    medians = np.append(medians,x_bootsorted[int(len(x_bootsorted)/2)])\n",
    "np.mean(medians)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above value is the estimate for $\\hat{\\mu}_{med}$ and the value below is its standrard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017087311243539648"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(medians)/np.power(n,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.01"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medvsorted = sorted(medv)\n",
    "np.quantile(medvsorted,.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.9732650000000005, 0.025674171314335855)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_times = 1000\n",
    "n = len(df)\n",
    "tpcntl = np.array([])\n",
    "for i in range(B_times):\n",
    "    x_bootstrap = choices(medv, k = n) ## draw samples with replacement\n",
    "    x_bootsorted = sorted(x_bootstrap)\n",
    "    tpcntl = np.append(tpcntl,np.quantile(x_bootsorted,.01))\n",
    "    \n",
    "np.mean(tpcntl),np.std(tpcntl)/np.power(n,.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for parts h and g i have printeed out the mean of the all the samples for that specific parameter along with its standard error.\n",
    "- $\\hat{\\mu}_{med}$ = 21.199799 and the SE = 0.01708731\n",
    "- $\\hat{\\mu}_{0.1}$ = 6.973265 and the SE = 0.0256741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: (Theoretical  and programing question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now derive the probability that a given observation is part\n",
    "of a bootstrap sample. Suppose that we obtain a bootstrap sample\n",
    "from a set of $n$ observations.\n",
    "\n",
    "(a) What is the probability that the first bootstrap observation is\n",
    "_not_ the $j$th observation from the original sample? Justify your\n",
    "answer.\n",
    "\n",
    "(b) What is the probability that the second bootstrap observation\n",
    "is _not_ the $j$th observation from the original sample?\n",
    "\n",
    "(c) Argue that the probability that the $j$th observation is not in the\n",
    "bootstrap sample is $(1 − 1/n)^n$.\n",
    "\n",
    "(d) When $n = 5$, what is the probability that the $j$th observation is\n",
    "in the bootstrap sample?\n",
    "\n",
    "(e) When $n = 100$, what is the probability that the $j$th observation\n",
    "is in the bootstrap sample?\n",
    "\n",
    "(f) When $n = 10, 000$, what is the probability that the $j$th observation\n",
    "is in the bootstrap sample?\n",
    "\n",
    "(g) Create a plot that displays, for each integer value of $n$ from 1\n",
    "to 100, 000, the probability that the jth observation is in the\n",
    "bootstrap sample. Comment on what you observe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe12f45fc40>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 100000   # Number of observations\n",
    "prob = [1 - (1-1/n)**n for n in range(1, n)] # If the body of the loop is short, we can use this method\n",
    "x = [n for n in range(1, n)]\n",
    " \n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "ax.plot(x, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### your analysis here:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a \n",
    "    - the probability that the jth observation is not in the in the origonal sample is 1-1/n . when taking our first bootstrap sample each observaation has a equal probability, and becuase we are interested in the not case we then put 1-1/n.\n",
    "- b \n",
    "    - so the second bootstrap sample has each observation with a probability of 1/n , it would be n-1 but there is replacement so the probability stays the same .\n",
    "- c \n",
    "    - so for the first sample the P(j) to not be in the sample is 1-1/n, this can be applied to each redraw becuase there is replacement in these samples. because these selections are random and independent we can say that the P(j) is not in the nth sample is the same as multiplying all the prior probabilities, and since there are n samples we can get (1-1/n) ^N\n",
    "- d\n",
    "    - becuase we want the opposite probability of the equation we just described we can say 1-(1-1/n)^n is the probability the th observation is in the sample when n =5 the probability is = .67232 and the same process can be done with 100 and 10000 where when n = 100 the P(j is in the sample) = .633967 and when n=10000, the  P(j is in the sample ) = .632138\n",
    "- g \n",
    "     - the graph shows that as our sample size increases the probability of j being in the sample approaches a hard limit somewhere above 0. this limit must be 1-1/e as this is approximately 1-p(observation isnt in sample )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
